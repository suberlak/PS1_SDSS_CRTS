{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MCMC on simulated S82 LCs, as well as MAP.  \n",
    "\n",
    "Storing both the full chains, MAP estimates, and logL evaluated on  a grid . \n",
    "\n",
    "Do all for Jeff2 , same prior as used by Kozlowski (if needed, can repeat with the other prior too )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams \n",
    "from astroML.plotting.mcmc import convert_to_stdev\n",
    "from astroML.datasets import fetch_dr7_quasar\n",
    "import celerite\n",
    "from celerite import terms\n",
    "from astropy.table import Table\n",
    "from astropy.table import vstack\n",
    "from astropy.table import Column\n",
    "import emcee\n",
    "rcParams['ytick.labelsize'] = 15\n",
    "rcParams['xtick.labelsize'] = 15\n",
    "rcParams['axes.labelsize'] = 20\n",
    "rcParams['axes.linewidth'] = 2\n",
    "rcParams['font.size'] = 15\n",
    "rcParams['axes.titlesize'] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate SDSS light curves over 8 years , 60 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_exp = 8 * 365 # days \n",
    "rho_in = np.array([0.001, 15])\n",
    "tau_in = rho_in * t_exp\n",
    "print(' %.2f < tau_in < %.2f  [days]'% (tau_in[0], tau_in[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the negative log likelihood\n",
    "def neg_log_posterior(params,y,gp,prior):\n",
    "    if prior is 'None' : \n",
    "        gp.set_parameter_vector(params)\n",
    "        return -gp.log_likelihood(y, quiet=True)\n",
    "\n",
    "    if prior is 'Jeff1' : # (1/sigma) * (1/tau) \n",
    "        gp.set_parameter_vector(params)\n",
    "        log_a  , log_c =  params\n",
    "        log_prior = - (log_a / 2.0) + log_c\n",
    "        return -gp.log_likelihood(y, quiet=True) - log_prior\n",
    "\n",
    "    if prior is 'Jeff2' : # (1/sigma_hat) * (1/tau) - the one used by Kozlowski , \n",
    "        # as well as Chelsea... \n",
    "        gp.set_parameter_vector(params)\n",
    "        log_a  , log_c =  params\n",
    "        log_prior  = 0.5* (-np.log(2.0) - log_a + log_c  )\n",
    "        return -gp.log_likelihood(y, quiet=True)  - log_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the Celerite kernel : \n",
    "# same for all light curves ... \n",
    "# doesn't matter what it is initialized with \n",
    "kernel = terms.RealTerm(log_a = 2 * np.log(0.2) , \n",
    "                        log_c = np.log(1.0/100))\n",
    "SF_inf = 0.2 # mag \n",
    "t_exp = 8 * 365.0 # in days \n",
    "rho_min, rho_max,  n_rho = 0.001, 15, 100\n",
    "rho_grid = np.logspace(np.log10(rho_min), np.log10(rho_max), n_rho)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chris/GradResearch/Paper2_SDSS_PTF_PS1/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simulation = 'SDSS'\n",
    "if simulation is 'SDSS' : \n",
    "    r = 17 # mag \n",
    "    variance = 0.013**2.0 + np.exp(2 * (r-23.36))\n",
    "    t = np.loadtxt('t_SDSS.txt')\n",
    "if simulation is 'OGLE' : \n",
    "    I = 18 # mag \n",
    "    variance = 0.004**2.0 + np.exp(1.63 * (I - 22.55))    \n",
    "    t =  np.loadtxt('t_OGLE.txt')\n",
    "        \n",
    "#print(simulation,' noise stdev ', np.sqrt(variance))\n",
    "\n",
    "# set the light curve directory \n",
    "outDir = '../data_products/Simulated_DRW_Kozlowski/'+simulation+'/'\n",
    "\n",
    "# set the output directory \n",
    "resDir  = '../data_products/Simulated_DRW_Kozlowski/'+simulation+'/thursday_work/'\n",
    "        \n",
    "        \n",
    "def fit_lightcurve(t,y,yerr,kernel,chain_name, results_name, SF_inf, tau_in,\n",
    "                   prior='Jeff2',\n",
    "                  sig_lims =[0.02, 0.7], tau_lims = [1,40000],\n",
    "                  verbose=True):\n",
    "            \n",
    "    results = {}\n",
    "    sigma_in = SF_inf / np.sqrt(2)\n",
    "    results['sigma_in'] = sigma_in\n",
    "    results['tau_in'] = tau_in\n",
    "    \n",
    "    if verbose:\n",
    "        print('sigma_in=' ,sigma_in, 'tau_in=', tau_in)\n",
    "        \n",
    "    #log_a, log_c =  2 * np.log(sigma_in),np.log(1.0/tau_in) \n",
    "    #truths = [log_a, log_c]\n",
    "    \n",
    "    # Find MAP solution with Celerite \n",
    "    # call the model  with a chosen kernel instance \n",
    "    gp = celerite.GP(kernel, mean=np.mean(y))\n",
    "    gp.compute(t, yerr)\n",
    "\n",
    "    # set initial params \n",
    "    initial_params = gp.get_parameter_vector()\n",
    "\n",
    "    # boundaries for the MAP estimate \n",
    "    logc_bounds= (np.log(1/max(tau_lims)), \n",
    "                  np.log(1/min(tau_lims)) )\n",
    "    loga_bounds = (2*np.log(min(sig_lims)), \n",
    "                   2*np.log(max(sig_lims)))\n",
    "    bounds = [loga_bounds, logc_bounds]\n",
    "            \n",
    "    # calculate \n",
    "    gp = celerite.GP(kernel, mean=np.mean(y))\n",
    "    gp.compute(t, yerr)\n",
    "\n",
    "     # set initial params \n",
    "    initial_params = gp.get_parameter_vector()\n",
    "             \n",
    "    # wrap the neg_log_posterior for a chosen prior \n",
    "    def neg_log_like(params,y,gp):\n",
    "        return neg_log_posterior(params,y,gp,prior)\n",
    "\n",
    "    # find MAP solution \n",
    "    r = minimize(neg_log_like, initial_params, \n",
    "             method=\"L-BFGS-B\", bounds=bounds, args=(y, gp))\n",
    "    gp.set_parameter_vector(r.x)\n",
    "    res = gp.get_parameter_dict()\n",
    "\n",
    "    tau_fit = np.exp(-res['kernel:log_c'])\n",
    "    sigma_fit = np.exp(res['kernel:log_a']/2)\n",
    "    results['tau_MAP'] = tau_fit\n",
    "    results['sigma_MAP'] = sigma_fit\n",
    "    \n",
    "    if verbose : \n",
    "        print('MAP ')\n",
    "        print('sigma_fit', sigma_fit,'tau_fit', tau_fit)\n",
    "              \n",
    "            \n",
    "    # evaluate logP\n",
    "    Ngrid = 60 \n",
    "    sigma_grid = np.linspace(sig_lims[0], sig_lims[1],Ngrid )\n",
    "    tau_grid  = np.linspace(tau_lims[0], tau_lims[1], Ngrid)\n",
    "    logP = evaluate_logP(sigma_grid, tau_grid,y,gp)\n",
    "    results['logP'] = logP\n",
    "    results['sigma_grid'] = sigma_grid\n",
    "    results['tau_grid'] = tau_grid\n",
    "    \n",
    "    ######\n",
    "    ######  MCMC \n",
    "    ###### \n",
    "\n",
    "    # wrap the neg_log_posterior for this \n",
    "    def log_probability(params,y,gp,prior):\n",
    "        return -neg_log_posterior(params,y,gp,prior)\n",
    "\n",
    "    # set the initial chain position on the MAP value \n",
    "    initial = np.array(r.x)\n",
    "    ndim, nwalkers = len(initial), 32\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim,  log_probability,\n",
    "                                   args=(y,gp,prior))\n",
    "\n",
    "    print(\"Running burn-in...\")\n",
    "    p0 = initial + 1e-8 * np.random.randn(nwalkers, ndim)\n",
    "    p0, lp, _ = sampler.run_mcmc(p0, 500)\n",
    "\n",
    "    print(\"Running production...\")\n",
    "    sampler.reset()\n",
    "    sampler.run_mcmc(p0, 2000);\n",
    "    print(\"Done\")\n",
    "\n",
    "    # Store the chains \n",
    "    samples = sampler.flatchain\n",
    "    np.savetxt(resDir+chain_name,samples )\n",
    "    \n",
    "    # Store the median and 16th, 84th percentiles \n",
    "    inds = np.array([0,1])\n",
    "    log_a,log_c = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]),\n",
    "                             zip(*np.percentile(samples[:, inds]\n",
    "                                                , [16, 50, 84],\n",
    "                                                axis=0)))\n",
    "\n",
    "    tau_MCMC_mode, tau_hi, tau_lo = np.exp(-np.asarray(log_c))\n",
    "    sigma_MCMC_mode ,sigma_hi, sigma_lo= np.exp(np.asarray(log_a)/2)\n",
    "    \n",
    "    results['tau_MCMC'] = tau_MCMC_mode\n",
    "    results['sigma_MCMC'] = sigma_MCMC_mode\n",
    "    results['tau_PM'] = [tau_lo, tau_hi]\n",
    "    results['sigma_PM'] = [sigma_lo, sigma_hi]\n",
    "    \n",
    "    if verbose : \n",
    "        print('the MCMC result for tau is ', tau_MCMC_mode, '+', \n",
    "              tau_hi, '-', tau_lo)\n",
    "        print('the MCMC result for sigma is ', sigma_MCMC_mode, '+', \n",
    "              sigma_hi, '-', sigma_lo)\n",
    "    \n",
    "    # Save all the results \n",
    "    np.save(resDir  + results_name, results)\n",
    "    if verbose:\n",
    "        print(' Saved logP (and MAP) dic as %s'%results_name)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_logP(sigma_grid, tau_grid, y,gp, prior='None'):\n",
    "    \n",
    "    log_a_grid = 2 * np.log(sigma_grid)\n",
    "    log_c_grid = np.log(1/tau_grid)\n",
    "\n",
    "    # loop over the likelihood space .... \n",
    "    logPosterior = np.zeros([len(sigma_grid),len(tau_grid)], \n",
    "                            dtype=float)\n",
    "    for k in range(len(log_a_grid)):\n",
    "        for l in range(len(log_c_grid)):\n",
    "            params = [log_a_grid[k],log_c_grid[l]]    \n",
    "            logPosterior[k,l] = -neg_log_posterior(params,y,gp, prior)\n",
    "    return logPosterior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# read in the light curves\n",
    "for i in range(54,55)#len(rho_grid)): \n",
    "    rho_in = rho_grid[i]\n",
    "    tau_in = rho_in * t_exp\n",
    "    if i % 10 == 0 : \n",
    "        print(i)\n",
    "    # for each rho, read in  N light curves \n",
    "    for j in range(74,100):\n",
    "        fname = 'DRW_rho-' + str(i).zfill(3)+'_'+str(j).zfill(3)+'.txt'\n",
    "        y = np.loadtxt(outDir+fname)\n",
    "        # make a random draw from a Gaussian distribution\n",
    "        # centered on 0,\n",
    "        # with variance set by the equation from Kozlowski+2017\n",
    "        # variance is different for OGLE or  SDSS \n",
    "        noise = np.random.normal(loc=0,scale=np.sqrt(variance),size=len(t))\n",
    "        y += noise +10 # eq.2 Kozlowski+2017\n",
    "\n",
    "        # the uncertainty on each measurement : \n",
    "        # I set it to sigma_SDSS = 0.0248, or sigma_OGLE = 0.0131,\n",
    "        # homoscedastic, i.e. same errors for all points \n",
    "        yerr = np.ones_like(t)* np.sqrt(variance)\n",
    "        chain_name = fname[:-4]+'_chain.txt'\n",
    "        results_name = fname[:-4]+'_logP.npy'\n",
    "        \n",
    "        # call the MAP, MCMC fitting code \n",
    "        fit_lightcurve(t,y,yerr,kernel,chain_name, results_name, SF_inf, tau_in,\n",
    "                       prior='Jeff2',\n",
    "                      sig_lims =[0.02, 0.7], tau_lims = [1,40000],\n",
    "                      verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
